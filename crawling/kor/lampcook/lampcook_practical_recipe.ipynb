{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음식명 추출 함수\n",
    "def extract_recipe_names(url):\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content.decode('utf-8', 'ignore')\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    recipe_names = []\n",
    "\n",
    "    title_div = soup.find('div', class_='item_box_data2')\n",
    "    title_li = title_div.find_all('li', class_='item_box_thum_content')\n",
    "\n",
    "    for name in title_li:\n",
    "        recipe_name_element = name.find('h2', class_='h2_padd0')\n",
    "        if recipe_name_element:\n",
    "            recipe_name = recipe_name_element.text.strip()\n",
    "            recipe_names.append(recipe_name)\n",
    "\n",
    "    return recipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레시피 추출 함수 - 레시피 단계에서 불필요한 문자가 존재하여 동시에 전처리 진행\n",
    "def extract_desired_content(soup):\n",
    "    desired_content = []\n",
    "    \n",
    "    # 모든 div 태그 중 class가 'padd20'인 것을 찾음\n",
    "    divs = soup.find_all('div', class_='padd20')\n",
    "    \n",
    "    # 각 div에서 텍스트 추출\n",
    "    for div in divs:\n",
    "        text = div.get_text(strip=True)\n",
    "        \n",
    "        # 불필요한 문자 제거\n",
    "        text = text.replace('？', '').replace('<', '').replace('>', '')\n",
    "        \n",
    "        # 원하는 내용 추출\n",
    "        if text.startswith(('1.', '2.', '3.', '4.', '5.')):\n",
    "            desired_content.append(text)\n",
    "    \n",
    "    return desired_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_data = [] # 크롤링한 데이터를 저장할 리스트 선언\n",
    "\n",
    "for i in range(1, 55):\n",
    "    url = f\"http://www.lampcook.com/food/food_fusion_list.php?search_mode=0&alpha_no=0&big_no=0&field_one=&sql_one=&pagenum={i}\"\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content.decode('utf-8', 'ignore')\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    recipe_names = extract_recipe_names(url)\n",
    "\n",
    "    link_div = soup.find('div', class_='item_box_data2')\n",
    "    link_li = link_div.find_all('li', class_='item_box_thum')\n",
    "\n",
    "    for i, card in enumerate(link_li):\n",
    "        relative_link = card.find('a')['href']\n",
    "        absolute_link = f\"http://www.lampcook.com/{relative_link}\"\n",
    "\n",
    "        response = requests.get(absolute_link)\n",
    "        html_content = response.content.decode('utf-8', 'ignore')\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        padd20 = soup.find_all('div', class_='padd20')\n",
    "        ingredients_list = []\n",
    "\n",
    "        for div in padd20:\n",
    "            br_tags = div.find_all('br')\n",
    "            for br in br_tags:\n",
    "                next_sib = br.next_sibling\n",
    "                if next_sib and isinstance(next_sib, str):\n",
    "                    ingredients_list.extend([ingredient.strip() for ingredient in next_sib.split(',') if ingredient.strip()])\n",
    "\n",
    "        for val in ingredients_list:\n",
    "            if val == \"<부재료>\":\n",
    "                ingredients_list.remove(val)\n",
    "            if val == \"<양념>\":\n",
    "                ingredients_list.remove(val)\n",
    "\n",
    "        desired_content = extract_desired_content(soup)\n",
    "\n",
    "        food_data.append({\n",
    "            \"name\": recipe_names[i],\n",
    "            \"url\": absolute_link,\n",
    "            \"ingredients\": ingredients_list,\n",
    "            \"recipe\": desired_content\n",
    "        })\n",
    "\n",
    "for data in food_data:\n",
    "    print(\"Name:\", data[\"name\"])\n",
    "    print(\"URL:\", data[\"url\"])\n",
    "    print(\"Ingredients:\", data[\"ingredients\"])\n",
    "    print(\"Recipe:\")\n",
    "    for content in data[\"recipe\"]:\n",
    "        print(content)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lampcook.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # CSV 파일의 헤더 작성\n",
    "    writer.writerow(['Name', 'URL', 'Ingredients', 'Recipe'])\n",
    "    \n",
    "    # food_data 리스트에 있는 데이터를 CSV 파일에 기록\n",
    "    for data in food_data:\n",
    "        name = data[\"name\"]\n",
    "        url = data[\"url\"]\n",
    "        ingredients = ', '.join(data[\"ingredients\"])\n",
    "        recipe = ', '.join(data[\"recipe\"])\n",
    "        \n",
    "        # 각 항목을 CSV 파일에 작성\n",
    "        writer.writerow([name, url, ingredients, recipe])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
